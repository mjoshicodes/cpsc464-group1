{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from datasets.risk_score import RiskDataset\n",
    "\n",
    "# Datasets\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.datasets import MEPSDataset20\n",
    "from aif360.datasets import MEPSDataset21\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Explainers\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Bias mitigation techniques\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "\n",
    "# LIME\n",
    "from aif360.datasets.lime_encoder import LimeEncoder\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aif360.datasets.meps_dataset_panel19_fy2015.MEPSDataset19"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(MEPSDataset19())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.risk_score import RiskDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/megha/Fall_2022/CPSC464/Git/cpsc464-group1/data/data_added.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 41873 rows removed from RiskDataset.\n"
     ]
    }
   ],
   "source": [
    "mydata = RiskDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = MEPSDataset19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset_orig_panel19_train,\n",
    " dataset_orig_panel19_val,\n",
    " dataset_orig_panel19_test) = MEPSDataset19().split([0.5, 0.8], shuffle=True)\n",
    "\n",
    "sens_ind = 0\n",
    "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
    "\n",
    "unprivileged_groups = [{sens_attr: v} for v in\n",
    "                       dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]]\n",
    "privileged_groups = [{sens_attr: v} for v in\n",
    "                     dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StandardDataset.__init__() missing 4 required positional arguments: 'label_name', 'favorable_classes', 'protected_attribute_names', and 'privileged_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m StandardDataset(df)\n",
      "\u001b[0;31mTypeError\u001b[0m: StandardDataset.__init__() missing 4 required positional arguments: 'label_name', 'favorable_classes', 'protected_attribute_names', and 'privileged_classes'"
     ]
    }
   ],
   "source": [
    "StandardDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[39m.\u001b[39;49msplit\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:5907\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5901\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5902\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5903\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5904\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5905\u001b[0m ):\n\u001b[1;32m   5906\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "df.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/megha/Fall_2022/CPSC464/Git/cpsc464-group1/data/data_added.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 41873 rows removed from RiskDataset.\n"
     ]
    }
   ],
   "source": [
    "(dataset_orig_panel19_train,\n",
    " dataset_orig_panel19_val,\n",
    " dataset_orig_panel19_test) = RiskDataset().split([0.5, 0.8], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_ind = 0\n",
    "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
    "\n",
    "unprivileged_groups = [{sens_attr: v} for v in\n",
    "                       dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]]\n",
    "privileged_groups = [{sens_attr: v} for v in\n",
    "                     dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'race': 1.0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privileged_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(train=None, val=None, test=None):\n",
    "    if train is not None:\n",
    "        display(Markdown(\"#### Training Dataset shape\"))\n",
    "        print(train.features.shape)\n",
    "    if val is not None:\n",
    "        display(Markdown(\"#### Validation Dataset shape\"))\n",
    "        print(val.features.shape)\n",
    "    display(Markdown(\"#### Test Dataset shape\"))\n",
    "    print(test.features.shape)\n",
    "    display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "    print(test.favorable_label, test.unfavorable_label)\n",
    "    display(Markdown(\"#### Protected attribute names\"))\n",
    "    print(test.protected_attribute_names)\n",
    "    display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "    print(test.privileged_protected_attributes, \n",
    "          test.unprivileged_protected_attributes)\n",
    "    display(Markdown(\"#### Dataset feature names\"))\n",
    "    print(test.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3455, 231)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Validation Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073, 231)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Test Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1383, 231)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'risk_score_t', 'program_enrolled_t', 'cost_avoidable_t', 'bps_mean_t', 'ghba1c_mean_t', 'hct_mean_t', 'cre_mean_t', 'ldl_mean_t', 'race', 'dem_female', 'dem_age_band_18-24_tm1', 'dem_age_band_25-34_tm1', 'dem_age_band_35-44_tm1', 'dem_age_band_45-54_tm1', 'dem_age_band_55-64_tm1', 'dem_age_band_65-74_tm1', 'dem_age_band_75+_tm1', 'alcohol_elixhauser_tm1', 'anemia_elixhauser_tm1', 'arrhythmia_elixhauser_tm1', 'arthritis_elixhauser_tm1', 'bloodlossanemia_elixhauser_tm1', 'coagulopathy_elixhauser_tm1', 'compdiabetes_elixhauser_tm1', 'depression_elixhauser_tm1', 'drugabuse_elixhauser_tm1', 'electrolytes_elixhauser_tm1', 'hypertension_elixhauser_tm1', 'hypothyroid_elixhauser_tm1', 'liver_elixhauser_tm1', 'neurodegen_elixhauser_tm1', 'obesity_elixhauser_tm1', 'paralysis_elixhauser_tm1', 'psychosis_elixhauser_tm1', 'pulmcirc_elixhauser_tm1', 'pvd_elixhauser_tm1', 'renal_elixhauser_tm1', 'uncompdiabetes_elixhauser_tm1', 'valvulardz_elixhauser_tm1', 'wtloss_elixhauser_tm1', 'cerebrovasculardz_romano_tm1', 'chf_romano_tm1', 'dementia_romano_tm1', 'hemiplegia_romano_tm1', 'hivaids_romano_tm1', 'metastatic_romano_tm1', 'myocardialinfarct_romano_tm1', 'pulmonarydz_romano_tm1', 'tumor_romano_tm1', 'ulcer_romano_tm1', 'cost_dialysis_tm1', 'cost_emergency_tm1', 'cost_home_health_tm1', 'cost_ip_medical_tm1', 'cost_ip_surgical_tm1', 'cost_laboratory_tm1', 'cost_op_primary_care_tm1', 'cost_op_specialists_tm1', 'cost_op_surgery_tm1', 'cost_other_tm1', 'cost_pharmacy_tm1', 'cost_physical_therapy_tm1', 'cost_radiology_tm1', 'lasix_dose_count_tm1', 'lasix_min_daily_dose_tm1', 'lasix_mean_daily_dose_tm1', 'lasix_max_daily_dose_tm1', 'cre_tests_tm1', 'crp_tests_tm1', 'esr_tests_tm1', 'ghba1c_tests_tm1', 'hct_tests_tm1', 'ldl_tests_tm1', 'nt_bnp_tests_tm1', 'sodium_tests_tm1', 'trig_tests_tm1', 'cre_min-low_tm1', 'cre_min-high_tm1', 'cre_min-normal_tm1', 'cre_mean-low_tm1', 'cre_mean-high_tm1', 'cre_mean-normal_tm1', 'cre_max-low_tm1', 'cre_max-high_tm1', 'cre_max-normal_tm1', 'crp_min-low_tm1', 'crp_min-high_tm1', 'crp_min-normal_tm1', 'crp_mean-low_tm1', 'crp_mean-high_tm1', 'crp_mean-normal_tm1', 'crp_max-low_tm1', 'crp_max-high_tm1', 'crp_max-normal_tm1', 'esr_min-low_tm1', 'esr_min-high_tm1', 'esr_min-normal_tm1', 'esr_mean-low_tm1', 'esr_mean-high_tm1', 'esr_mean-normal_tm1', 'esr_max-low_tm1', 'esr_max-high_tm1', 'esr_max-normal_tm1', 'ghba1c_min-low_tm1', 'ghba1c_min-high_tm1', 'ghba1c_min-normal_tm1', 'ghba1c_mean-low_tm1', 'ghba1c_mean-high_tm1', 'ghba1c_mean-normal_tm1', 'ghba1c_max-low_tm1', 'ghba1c_max-high_tm1', 'ghba1c_max-normal_tm1', 'hct_min-low_tm1', 'hct_min-high_tm1', 'hct_min-normal_tm1', 'hct_mean-low_tm1', 'hct_mean-high_tm1', 'hct_mean-normal_tm1', 'hct_max-low_tm1', 'hct_max-high_tm1', 'hct_max-normal_tm1', 'ldl_min-low_tm1', 'ldl_min-high_tm1', 'ldl_min-normal_tm1', 'ldl-mean-low_tm1', 'ldl-mean-high_tm1', 'ldl-mean-normal_tm1', 'ldl_max-low_tm1', 'ldl_max-high_tm1', 'ldl_max-normal_tm1', 'nt_bnp_min-low_tm1', 'nt_bnp_min-high_tm1', 'nt_bnp_min-normal_tm1', 'nt_bnp_mean-low_tm1', 'nt_bnp_mean-high_tm1', 'nt_bnp_mean-normal_tm1', 'nt_bnp_max-low_tm1', 'nt_bnp_max-high_tm1', 'nt_bnp_max-normal_tm1', 'sodium_min-low_tm1', 'sodium_min-high_tm1', 'sodium_min-normal_tm1', 'sodium_mean-low_tm1', 'sodium_mean-high_tm1', 'sodium_mean-normal_tm1', 'sodium_max-low_tm1', 'sodium_max-high_tm1', 'sodium_max-normal_tm1', 'trig_min-low_tm1', 'trig_min-high_tm1', 'trig_min-normal_tm1', 'trig_mean-low_tm1', 'trig_mean-high_tm1', 'trig_mean-normal_tm1', 'trig_max-low_tm1', 'trig_max-high_tm1', 'trig_max-normal_tm1', 'gagne_sum_tm1=0', 'gagne_sum_tm1=1', 'gagne_sum_tm1=2', 'gagne_sum_tm1=3', 'gagne_sum_tm1=4', 'gagne_sum_tm1=5', 'gagne_sum_tm1=6', 'gagne_sum_tm1=7', 'gagne_sum_tm1=8', 'gagne_sum_tm1=9', 'gagne_sum_tm1=10', 'gagne_sum_tm1=11', 'gagne_sum_tm1=12', 'gagne_sum_tm1=13', 'gagne_sum_tm1=14', 'gagne_sum_tm1=15', 'gagne_sum_tm1=16', 'gagne_sum_tm1=17', 'gagne_sum_t=0', 'gagne_sum_t=1', 'gagne_sum_t=2', 'gagne_sum_t=3', 'gagne_sum_t=4', 'gagne_sum_t=5', 'gagne_sum_t=6', 'gagne_sum_t=7', 'gagne_sum_t=8', 'gagne_sum_t=9', 'gagne_sum_t=10', 'gagne_sum_t=11', 'gagne_sum_t=12', 'gagne_sum_t=13', 'gagne_sum_t=14', 'gagne_sum_t=15', 'gagne_sum_t=16', 'gagne_sum_t=17', 'our_gagne_score=-2', 'our_gagne_score=-1', 'our_gagne_score=0', 'our_gagne_score=1', 'our_gagne_score=2', 'our_gagne_score=3', 'our_gagne_score=4', 'our_gagne_score=5', 'our_gagne_score=6', 'our_gagne_score=7', 'our_gagne_score=8', 'our_gagne_score=9', 'our_gagne_score=10', 'our_gagne_score=11', 'our_gagne_score=13', 'our_gagne_score=14', 'our_gagne_score=15', 'our_gagne_score=16', 'our_cci_score=0', 'our_cci_score=1', 'our_cci_score=2', 'our_cci_score=3', 'our_cci_score=4', 'our_cci_score=5', 'our_cci_score=6', 'our_cci_score=7', 'our_cci_score=8', 'our_cci_score=9', 'our_cci_score=10', 'our_cci_score=11', 'our_cci_score=12', 'our_cci_score=13', 'our_cci_score=14', 'our_cci_score=16', 'our_cci_score=17', 'our_cci_score=18', 'our_cci_score=20']\n"
     ]
    }
   ],
   "source": [
    "describe(dataset_orig_panel19_train, dataset_orig_panel19_val, dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metric_orig_panel19_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m explainer_orig_panel19_train \u001b[39m=\u001b[39m MetricTextExplainer(metric_orig_panel19_train)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(explainer_orig_panel19_train\u001b[39m.\u001b[39mdisparate_impact())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metric_orig_panel19_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "explainer_orig_panel19_train = MetricTextExplainer(metric_orig_panel19_train)\n",
    "\n",
    "print(explainer_orig_panel19_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_panel19_train = BinaryLabelDatasetMetric(\n",
    "        dataset_orig_panel19_train,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aif360.metrics.binary_label_dataset_metric.BinaryLabelDatasetMetric at 0x134fb01c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_orig_panel19_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[39m=\u001b[39m make_pipeline(StandardScaler(),\n\u001b[1;32m      4\u001b[0m                       LogisticRegression(solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m      5\u001b[0m fit_params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mlogisticregression__sample_weight\u001b[39m\u001b[39m'\u001b[39m: dataset\u001b[39m.\u001b[39minstance_weights}\n\u001b[0;32m----> 7\u001b[0m lr_orig_panel19 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(dataset\u001b[39m.\u001b[39;49mfeatures, dataset\u001b[39m.\u001b[39;49mlabels\u001b[39m.\u001b[39;49mravel(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1158\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[39mif\u001b[39;00m effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1153\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1154\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m > 1 does not have any effect when\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1155\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39msolver\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is set to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Got \u001b[39m\u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1156\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs))\n\u001b[1;32m   1157\u001b[0m         )\n\u001b[0;32m-> 1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _fit_liblinear(\n\u001b[1;32m   1159\u001b[0m         X,\n\u001b[1;32m   1160\u001b[0m         y,\n\u001b[1;32m   1161\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m   1162\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1163\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintercept_scaling,\n\u001b[1;32m   1164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpenalty,\n\u001b[1;32m   1166\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdual,\n\u001b[1;32m   1167\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1168\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1169\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1171\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1172\u001b[0m     )\n\u001b[1;32m   1173\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39msag\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1162\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     classes_ \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m   1161\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(classes_) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 1162\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1163\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis solver needs samples of at least 2 classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1164\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m in the data, but the data contains only one\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1165\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m class: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1166\u001b[0m             \u001b[39m%\u001b[39m classes_[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1167\u001b[0m         )\n\u001b[1;32m   1169\u001b[0m     class_weight_ \u001b[39m=\u001b[39m compute_class_weight(class_weight, classes\u001b[39m=\u001b[39mclasses_, y\u001b[39m=\u001b[39my)\n\u001b[1;32m   1170\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0"
     ]
    }
   ],
   "source": [
    "lr_orig_panel19 = model.fit(dataset.features, dataset.labels.ravel(), **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(),\n",
    "                      LogisticRegression(solver='liblinear', random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(random_state=1, solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(random_state=1, solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(random_state=1, solver='liblinear'))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_orig_panel19_train\n",
    "fit_params = {'logisticregression__sample_weight': dataset.instance_weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights     features                     \\\n",
       "                                                                  \n",
       "                                risk_score_t program_enrolled_t   \n",
       "instance names                                                    \n",
       "14892                       1.0     3.855954                0.0   \n",
       "14310                       1.0    15.712587                0.0   \n",
       "12798                       1.0    12.332258                0.0   \n",
       "21292                       1.0     2.955665                0.0   \n",
       "1017                        1.0     1.019195                0.0   \n",
       "...                         ...          ...                ...   \n",
       "25340                       1.0     4.297605                0.0   \n",
       "15821                       1.0     1.002208                0.0   \n",
       "11602                       1.0     2.242229                0.0   \n",
       "25228                       1.0    14.183795                0.0   \n",
       "18150                       1.0     2.598947                0.0   \n",
       "\n",
       "                                                                     \\\n",
       "                                                                      \n",
       "               cost_avoidable_t bps_mean_t ghba1c_mean_t hct_mean_t   \n",
       "instance names                                                        \n",
       "14892                     300.0      135.0      5.900000  45.000000   \n",
       "14310                       0.0      152.0      5.600000  44.366667   \n",
       "12798                    8700.0      127.0      9.780000  43.240000   \n",
       "21292                    1400.0      121.0      5.500000  41.700000   \n",
       "1017                        0.0      105.0      5.000000  40.900000   \n",
       "...                         ...        ...           ...        ...   \n",
       "25340                       0.0      124.0      6.200000  41.700000   \n",
       "15821                    4900.0      102.0      5.500000  26.366667   \n",
       "11602                       0.0      130.0      5.800000  44.400000   \n",
       "25228                   74800.0      115.0      5.800000  25.933333   \n",
       "18150                       0.0      133.0      8.033333  46.000000   \n",
       "\n",
       "                                                           ...  \\\n",
       "                                      protected attribute  ...   \n",
       "               cre_mean_t  ldl_mean_t                race  ...   \n",
       "instance names                                             ...   \n",
       "14892            0.676667   64.000000                 1.0  ...   \n",
       "14310            1.060000  117.000000                 1.0  ...   \n",
       "12798            2.010000   29.666667                 1.0  ...   \n",
       "21292            0.806667  136.000000                 1.0  ...   \n",
       "1017             0.610000   98.000000                 1.0  ...   \n",
       "...                   ...         ...                 ...  ...   \n",
       "25340            0.825000  164.500000                 0.0  ...   \n",
       "15821            0.476000  138.500000                 0.0  ...   \n",
       "11602            0.820000  169.000000                 0.0  ...   \n",
       "25228            1.281613   98.000000                 1.0  ...   \n",
       "18150            1.150000  104.000000                 1.0  ...   \n",
       "\n",
       "                                                                         \\\n",
       "                                                                          \n",
       "               trig_min-normal_tm1 trig_mean-low_tm1 trig_mean-high_tm1   \n",
       "instance names                                                            \n",
       "14892                          0.0               0.0                0.0   \n",
       "14310                          0.0               0.0                1.0   \n",
       "12798                          0.0               0.0                1.0   \n",
       "21292                          1.0               0.0                0.0   \n",
       "1017                           0.0               0.0                0.0   \n",
       "...                            ...               ...                ...   \n",
       "25340                          0.0               0.0                0.0   \n",
       "15821                          0.0               0.0                0.0   \n",
       "11602                          0.0               0.0                0.0   \n",
       "25228                          0.0               0.0                0.0   \n",
       "18150                          0.0               0.0                1.0   \n",
       "\n",
       "                                                                        \\\n",
       "                                                                         \n",
       "               trig_mean-normal_tm1 trig_max-low_tm1 trig_max-high_tm1   \n",
       "instance names                                                           \n",
       "14892                           0.0              0.0               0.0   \n",
       "14310                           0.0              0.0               1.0   \n",
       "12798                           0.0              0.0               1.0   \n",
       "21292                           1.0              0.0               0.0   \n",
       "1017                            0.0              0.0               0.0   \n",
       "...                             ...              ...               ...   \n",
       "25340                           0.0              0.0               0.0   \n",
       "15821                           0.0              0.0               0.0   \n",
       "11602                           0.0              0.0               0.0   \n",
       "25228                           0.0              0.0               0.0   \n",
       "18150                           0.0              0.0               1.0   \n",
       "\n",
       "                                                             labels  \n",
       "                                                                     \n",
       "               trig_max-normal_tm1 gagne_sum_tm1 gagne_sum_t         \n",
       "instance names                                                       \n",
       "14892                          0.0           1.0         1.0    0.0  \n",
       "14310                          0.0           5.0         5.0    0.0  \n",
       "12798                          0.0           4.0         6.0    0.0  \n",
       "21292                          1.0           1.0         1.0    0.0  \n",
       "1017                           0.0           0.0         0.0    0.0  \n",
       "...                            ...           ...         ...    ...  \n",
       "25340                          0.0           4.0         3.0    0.0  \n",
       "15821                          0.0           0.0         0.0    0.0  \n",
       "11602                          0.0           1.0         1.0    0.0  \n",
       "25228                          0.0           4.0         9.0    0.0  \n",
       "18150                          0.0           1.0         1.0    0.0  \n",
       "\n",
       "[3455 rows x 161 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_params\n",
    "dataset_orig_panel19_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def test(dataset, model, thresh_arr):\n",
    "    try:\n",
    "        # sklearn classifier\n",
    "        y_val_pred_prob = model.predict_proba(dataset.features)\n",
    "        pos_ind = np.where(model.classes_ == dataset.favorable_label)[0][0]\n",
    "    except AttributeError:\n",
    "        # aif360 inprocessing algorithm\n",
    "        y_val_pred_prob = model.predict(dataset).scores\n",
    "        pos_ind = 0\n",
    "    \n",
    "    metric_arrs = defaultdict(list)\n",
    "    for thresh in thresh_arr:\n",
    "        y_val_pred = (y_val_pred_prob[:, pos_ind] > thresh).astype(np.float64)\n",
    "\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = y_val_pred\n",
    "        metric = ClassificationMetric(\n",
    "                dataset, dataset_pred,\n",
    "                unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "\n",
    "        metric_arrs['bal_acc'].append((metric.true_positive_rate()\n",
    "                                     + metric.true_negative_rate()) / 2)\n",
    "        metric_arrs['avg_odds_diff'].append(metric.average_odds_difference())\n",
    "        metric_arrs['disp_imp'].append(metric.disparate_impact())\n",
    "        metric_arrs['stat_par_diff'].append(metric.statistical_parity_difference())\n",
    "        metric_arrs['eq_opp_diff'].append(metric.equal_opportunity_difference())\n",
    "        metric_arrs['theil_ind'].append(metric.theil_index())\n",
    "    \n",
    "    return metric_arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_orig_panel19' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m thresh_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.01\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m50\u001b[39m)\n\u001b[1;32m      2\u001b[0m val_metrics \u001b[39m=\u001b[39m test(dataset\u001b[39m=\u001b[39mdataset_orig_panel19_val,\n\u001b[0;32m----> 3\u001b[0m                    model\u001b[39m=\u001b[39mlr_orig_panel19,\n\u001b[1;32m      4\u001b[0m                    thresh_arr\u001b[39m=\u001b[39mthresh_arr)\n\u001b[1;32m      5\u001b[0m lr_orig_best_ind \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(val_metrics[\u001b[39m'\u001b[39m\u001b[39mbal_acc\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr_orig_panel19' is not defined"
     ]
    }
   ],
   "source": [
    "thresh_arr = np.linspace(0.01, 0.5, 50)\n",
    "val_metrics = test(dataset=dataset_orig_panel19_val,\n",
    "                   model=lr_orig_panel19,\n",
    "                   thresh_arr=thresh_arr)\n",
    "lr_orig_best_ind = np.argmax(val_metrics['bal_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, x_name, y_left, y_left_name, y_right, y_right_name):\n",
    "    fig, ax1 = plt.subplots(figsize=(10,7))\n",
    "    ax1.plot(x, y_left)\n",
    "    ax1.set_xlabel(x_name, fontsize=16, fontweight='bold')\n",
    "    ax1.set_ylabel(y_left_name, color='b', fontsize=16, fontweight='bold')\n",
    "    ax1.xaxis.set_tick_params(labelsize=14)\n",
    "    ax1.yaxis.set_tick_params(labelsize=14)\n",
    "    ax1.set_ylim(0.5, 0.8)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x, y_right, color='r')\n",
    "    ax2.set_ylabel(y_right_name, color='r', fontsize=16, fontweight='bold')\n",
    "    if 'DI' in y_right_name:\n",
    "        ax2.set_ylim(0., 0.7)\n",
    "    else:\n",
    "        ax2.set_ylim(-0.25, 0.1)\n",
    "\n",
    "    best_ind = np.argmax(y_left)\n",
    "    ax2.axvline(np.array(x)[best_ind], color='k', linestyle=':')\n",
    "    ax2.yaxis.set_tick_params(labelsize=14)\n",
    "    ax2.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m disp_imp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mval_metrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp_imp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m disp_imp_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mminimum(disp_imp, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mdisp_imp)\n\u001b[1;32m      3\u001b[0m plot(thresh_arr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification Thresholds\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m      val_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbal_acc\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalanced Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m      disp_imp_err, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 - min(DI, 1/DI)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "disp_imp = np.array(val_metrics['disp_imp'])\n",
    "disp_imp_err = 1 - np.minimum(disp_imp, 1/disp_imp)\n",
    "plot(thresh_arr, 'Classification Thresholds',\n",
    "     val_metrics['bal_acc'], 'Balanced Accuracy',\n",
    "     disp_imp_err, '1 - min(DI, 1/DI)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plot(thresh_arr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification Thresholds\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 2\u001b[0m      \u001b[43mval_metrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbal_acc\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalanced Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m      val_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_odds_diff\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg. odds diff.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "plot(thresh_arr, 'Classification Thresholds',\n",
    "     val_metrics['bal_acc'], 'Balanced Accuracy',\n",
    "     val_metrics['avg_odds_diff'], 'avg. odds diff.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_metrics(metrics, thresh_arr):\n",
    "    best_ind = np.argmax(metrics['bal_acc'])\n",
    "    print(\"Threshold corresponding to Best balanced accuracy: {:6.4f}\".format(thresh_arr[best_ind]))\n",
    "    print(\"Best balanced accuracy: {:6.4f}\".format(metrics['bal_acc'][best_ind]))\n",
    "#     disp_imp_at_best_ind = np.abs(1 - np.array(metrics['disp_imp']))[best_ind]\n",
    "    disp_imp_at_best_ind = 1 - min(metrics['disp_imp'][best_ind], 1/metrics['disp_imp'][best_ind])\n",
    "    print(\"Corresponding 1-min(DI, 1/DI) value: {:6.4f}\".format(disp_imp_at_best_ind))\n",
    "    print(\"Corresponding average odds difference value: {:6.4f}\".format(metrics['avg_odds_diff'][best_ind]))\n",
    "    print(\"Corresponding statistical parity difference value: {:6.4f}\".format(metrics['stat_par_diff'][best_ind]))\n",
    "    print(\"Corresponding equal opportunity difference value: {:6.4f}\".format(metrics['eq_opp_diff'][best_ind]))\n",
    "    print(\"Corresponding Theil index value: {:6.4f}\".format(metrics['theil_ind'][best_ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_metrics(val_metrics, thresh_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_orig_metrics = test(dataset=dataset_orig_panel19_test,\n",
    "                       model=lr_orig_panel19,\n",
    "                       thresh_arr=[thresh_arr[lr_orig_best_ind]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_metrics(lr_orig_metrics, [thresh_arr[lr_orig_best_ind]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
