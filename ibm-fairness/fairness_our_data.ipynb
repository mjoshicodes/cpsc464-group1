{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from datasets.risk_score import RiskDataset\n",
    "\n",
    "# Datasets\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.datasets import MEPSDataset20\n",
    "from aif360.datasets import MEPSDataset21\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Explainers\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Bias mitigation techniques\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "\n",
    "# LIME\n",
    "from aif360.datasets.lime_encoder import LimeEncoder\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(MEPSDataset19())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.risk_score import RiskDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = RiskDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/megha/Fall_2022/CPSC464/Git/cpsc464-group1/data/data_new.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 41873 rows removed from RiskDataset.\n"
     ]
    }
   ],
   "source": [
    "(dataset_orig_panel19_train,\n",
    " dataset_orig_panel19_val,\n",
    " dataset_orig_panel19_test) = RiskDataset().split([0.5, 0.8], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_ind = 0\n",
    "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
    "\n",
    "unprivileged_groups = [{sens_attr: v} for v in\n",
    "                       dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]]\n",
    "privileged_groups = [{sens_attr: v} for v in\n",
    "                     dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(train=None, val=None, test=None):\n",
    "    if train is not None:\n",
    "        display(Markdown(\"#### Training Dataset shape\"))\n",
    "        print(train.features.shape)\n",
    "    if val is not None:\n",
    "        display(Markdown(\"#### Validation Dataset shape\"))\n",
    "        print(val.features.shape)\n",
    "    display(Markdown(\"#### Test Dataset shape\"))\n",
    "    print(test.features.shape)\n",
    "    display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "    print(test.favorable_label, test.unfavorable_label)\n",
    "    display(Markdown(\"#### Protected attribute names\"))\n",
    "    print(test.protected_attribute_names)\n",
    "    display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "    print(test.privileged_protected_attributes, \n",
    "          test.unprivileged_protected_attributes)\n",
    "    display(Markdown(\"#### Dataset feature names\"))\n",
    "    print(test.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3455, 159)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Validation Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073, 159)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Test Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1383, 159)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['risk_score_t', 'program_enrolled_t', 'cost_avoidable_t', 'bps_mean_t', 'ghba1c_mean_t', 'hct_mean_t', 'cre_mean_t', 'ldl_mean_t', 'race', 'dem_female', 'dem_age_band_18-24_tm1', 'dem_age_band_25-34_tm1', 'dem_age_band_35-44_tm1', 'dem_age_band_45-54_tm1', 'dem_age_band_55-64_tm1', 'dem_age_band_65-74_tm1', 'dem_age_band_75+_tm1', 'alcohol_elixhauser_tm1', 'anemia_elixhauser_tm1', 'arrhythmia_elixhauser_tm1', 'arthritis_elixhauser_tm1', 'bloodlossanemia_elixhauser_tm1', 'coagulopathy_elixhauser_tm1', 'compdiabetes_elixhauser_tm1', 'depression_elixhauser_tm1', 'drugabuse_elixhauser_tm1', 'electrolytes_elixhauser_tm1', 'hypertension_elixhauser_tm1', 'hypothyroid_elixhauser_tm1', 'liver_elixhauser_tm1', 'neurodegen_elixhauser_tm1', 'obesity_elixhauser_tm1', 'paralysis_elixhauser_tm1', 'psychosis_elixhauser_tm1', 'pulmcirc_elixhauser_tm1', 'pvd_elixhauser_tm1', 'renal_elixhauser_tm1', 'uncompdiabetes_elixhauser_tm1', 'valvulardz_elixhauser_tm1', 'wtloss_elixhauser_tm1', 'cerebrovasculardz_romano_tm1', 'chf_romano_tm1', 'dementia_romano_tm1', 'hemiplegia_romano_tm1', 'hivaids_romano_tm1', 'metastatic_romano_tm1', 'myocardialinfarct_romano_tm1', 'pulmonarydz_romano_tm1', 'tumor_romano_tm1', 'ulcer_romano_tm1', 'cost_dialysis_tm1', 'cost_emergency_tm1', 'cost_home_health_tm1', 'cost_ip_medical_tm1', 'cost_ip_surgical_tm1', 'cost_laboratory_tm1', 'cost_op_primary_care_tm1', 'cost_op_specialists_tm1', 'cost_op_surgery_tm1', 'cost_other_tm1', 'cost_pharmacy_tm1', 'cost_physical_therapy_tm1', 'cost_radiology_tm1', 'lasix_dose_count_tm1', 'lasix_min_daily_dose_tm1', 'lasix_mean_daily_dose_tm1', 'lasix_max_daily_dose_tm1', 'cre_tests_tm1', 'crp_tests_tm1', 'esr_tests_tm1', 'ghba1c_tests_tm1', 'hct_tests_tm1', 'ldl_tests_tm1', 'nt_bnp_tests_tm1', 'sodium_tests_tm1', 'trig_tests_tm1', 'cre_min-low_tm1', 'cre_min-high_tm1', 'cre_min-normal_tm1', 'cre_mean-low_tm1', 'cre_mean-high_tm1', 'cre_mean-normal_tm1', 'cre_max-low_tm1', 'cre_max-high_tm1', 'cre_max-normal_tm1', 'crp_min-low_tm1', 'crp_min-high_tm1', 'crp_min-normal_tm1', 'crp_mean-low_tm1', 'crp_mean-high_tm1', 'crp_mean-normal_tm1', 'crp_max-low_tm1', 'crp_max-high_tm1', 'crp_max-normal_tm1', 'esr_min-low_tm1', 'esr_min-high_tm1', 'esr_min-normal_tm1', 'esr_mean-low_tm1', 'esr_mean-high_tm1', 'esr_mean-normal_tm1', 'esr_max-low_tm1', 'esr_max-high_tm1', 'esr_max-normal_tm1', 'ghba1c_min-low_tm1', 'ghba1c_min-high_tm1', 'ghba1c_min-normal_tm1', 'ghba1c_mean-low_tm1', 'ghba1c_mean-high_tm1', 'ghba1c_mean-normal_tm1', 'ghba1c_max-low_tm1', 'ghba1c_max-high_tm1', 'ghba1c_max-normal_tm1', 'hct_min-low_tm1', 'hct_min-high_tm1', 'hct_min-normal_tm1', 'hct_mean-low_tm1', 'hct_mean-high_tm1', 'hct_mean-normal_tm1', 'hct_max-low_tm1', 'hct_max-high_tm1', 'hct_max-normal_tm1', 'ldl_min-low_tm1', 'ldl_min-high_tm1', 'ldl_min-normal_tm1', 'ldl-mean-low_tm1', 'ldl-mean-high_tm1', 'ldl-mean-normal_tm1', 'ldl_max-low_tm1', 'ldl_max-high_tm1', 'ldl_max-normal_tm1', 'nt_bnp_min-low_tm1', 'nt_bnp_min-high_tm1', 'nt_bnp_min-normal_tm1', 'nt_bnp_mean-low_tm1', 'nt_bnp_mean-high_tm1', 'nt_bnp_mean-normal_tm1', 'nt_bnp_max-low_tm1', 'nt_bnp_max-high_tm1', 'nt_bnp_max-normal_tm1', 'sodium_min-low_tm1', 'sodium_min-high_tm1', 'sodium_min-normal_tm1', 'sodium_mean-low_tm1', 'sodium_mean-high_tm1', 'sodium_mean-normal_tm1', 'sodium_max-low_tm1', 'sodium_max-high_tm1', 'sodium_max-normal_tm1', 'trig_min-low_tm1', 'trig_min-high_tm1', 'trig_min-normal_tm1', 'trig_mean-low_tm1', 'trig_mean-high_tm1', 'trig_mean-normal_tm1', 'trig_max-low_tm1', 'trig_max-high_tm1', 'trig_max-normal_tm1', 'gagne_sum_tm1', 'gagne_sum_t']\n"
     ]
    }
   ],
   "source": [
    "describe(dataset_orig_panel19_train, dataset_orig_panel19_val, dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    }
   ],
   "source": [
    "metric_orig_panel19_train = BinaryLabelDatasetMetric(\n",
    "        dataset_orig_panel19_train,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups)\n",
    "explainer_orig_panel19_train = MetricTextExplainer(metric_orig_panel19_train)\n",
    "\n",
    "print(explainer_orig_panel19_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m make_pipeline(StandardScaler(),\n\u001b[1;32m      3\u001b[0m                       LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      4\u001b[0m fit_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogisticregression__sample_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: dataset\u001b[38;5;241m.\u001b[39minstance_weights}\n\u001b[0;32m----> 6\u001b[0m lr_orig_panel19 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1158\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[39mif\u001b[39;00m effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1153\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1154\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m > 1 does not have any effect when\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1155\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39msolver\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is set to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Got \u001b[39m\u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1156\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs))\n\u001b[1;32m   1157\u001b[0m         )\n\u001b[0;32m-> 1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _fit_liblinear(\n\u001b[1;32m   1159\u001b[0m         X,\n\u001b[1;32m   1160\u001b[0m         y,\n\u001b[1;32m   1161\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m   1162\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1163\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintercept_scaling,\n\u001b[1;32m   1164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpenalty,\n\u001b[1;32m   1166\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdual,\n\u001b[1;32m   1167\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1168\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1169\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1171\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1172\u001b[0m     )\n\u001b[1;32m   1173\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39msag\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1162\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     classes_ \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m   1161\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(classes_) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 1162\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1163\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis solver needs samples of at least 2 classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1164\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m in the data, but the data contains only one\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1165\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m class: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1166\u001b[0m             \u001b[39m%\u001b[39m classes_[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1167\u001b[0m         )\n\u001b[1;32m   1169\u001b[0m     class_weight_ \u001b[39m=\u001b[39m compute_class_weight(class_weight, classes\u001b[39m=\u001b[39mclasses_, y\u001b[39m=\u001b[39my)\n\u001b[1;32m   1170\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0"
     ]
    }
   ],
   "source": [
    "dataset = dataset_orig_panel19_train\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      LogisticRegression(solver='liblinear', random_state=1))\n",
    "fit_params = {'logisticregression__sample_weight': dataset.instance_weights}\n",
    "\n",
    "lr_orig_panel19 = model.fit(dataset.features, dataset.labels.ravel(), **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def test(dataset, model, thresh_arr):\n",
    "    try:\n",
    "        # sklearn classifier\n",
    "        y_val_pred_prob = model.predict_proba(dataset.features)\n",
    "        pos_ind = np.where(model.classes_ == dataset.favorable_label)[0][0]\n",
    "    except AttributeError:\n",
    "        # aif360 inprocessing algorithm\n",
    "        y_val_pred_prob = model.predict(dataset).scores\n",
    "        pos_ind = 0\n",
    "    \n",
    "    metric_arrs = defaultdict(list)\n",
    "    for thresh in thresh_arr:\n",
    "        y_val_pred = (y_val_pred_prob[:, pos_ind] > thresh).astype(np.float64)\n",
    "\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = y_val_pred\n",
    "        metric = ClassificationMetric(\n",
    "                dataset, dataset_pred,\n",
    "                unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "\n",
    "        metric_arrs['bal_acc'].append((metric.true_positive_rate()\n",
    "                                     + metric.true_negative_rate()) / 2)\n",
    "        metric_arrs['avg_odds_diff'].append(metric.average_odds_difference())\n",
    "        metric_arrs['disp_imp'].append(metric.disparate_impact())\n",
    "        metric_arrs['stat_par_diff'].append(metric.statistical_parity_difference())\n",
    "        metric_arrs['eq_opp_diff'].append(metric.equal_opportunity_difference())\n",
    "        metric_arrs['theil_ind'].append(metric.theil_index())\n",
    "    \n",
    "    return metric_arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_orig_panel19' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m thresh_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      2\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m test(dataset\u001b[38;5;241m=\u001b[39mdataset_orig_panel19_val,\n\u001b[0;32m----> 3\u001b[0m                    model\u001b[38;5;241m=\u001b[39m\u001b[43mlr_orig_panel19\u001b[49m,\n\u001b[1;32m      4\u001b[0m                    thresh_arr\u001b[38;5;241m=\u001b[39mthresh_arr)\n\u001b[1;32m      5\u001b[0m lr_orig_best_ind \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(val_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbal_acc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr_orig_panel19' is not defined"
     ]
    }
   ],
   "source": [
    "thresh_arr = np.linspace(0.01, 0.5, 50)\n",
    "val_metrics = test(dataset=dataset_orig_panel19_val,\n",
    "                   model=lr_orig_panel19,\n",
    "                   thresh_arr=thresh_arr)\n",
    "lr_orig_best_ind = np.argmax(val_metrics['bal_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, x_name, y_left, y_left_name, y_right, y_right_name):\n",
    "    fig, ax1 = plt.subplots(figsize=(10,7))\n",
    "    ax1.plot(x, y_left)\n",
    "    ax1.set_xlabel(x_name, fontsize=16, fontweight='bold')\n",
    "    ax1.set_ylabel(y_left_name, color='b', fontsize=16, fontweight='bold')\n",
    "    ax1.xaxis.set_tick_params(labelsize=14)\n",
    "    ax1.yaxis.set_tick_params(labelsize=14)\n",
    "    ax1.set_ylim(0.5, 0.8)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x, y_right, color='r')\n",
    "    ax2.set_ylabel(y_right_name, color='r', fontsize=16, fontweight='bold')\n",
    "    if 'DI' in y_right_name:\n",
    "        ax2.set_ylim(0., 0.7)\n",
    "    else:\n",
    "        ax2.set_ylim(-0.25, 0.1)\n",
    "\n",
    "    best_ind = np.argmax(y_left)\n",
    "    ax2.axvline(np.array(x)[best_ind], color='k', linestyle=':')\n",
    "    ax2.yaxis.set_tick_params(labelsize=14)\n",
    "    ax2.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m disp_imp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mval_metrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp_imp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m disp_imp_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mminimum(disp_imp, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mdisp_imp)\n\u001b[1;32m      3\u001b[0m plot(thresh_arr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification Thresholds\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m      val_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbal_acc\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalanced Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m      disp_imp_err, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 - min(DI, 1/DI)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "disp_imp = np.array(val_metrics['disp_imp'])\n",
    "disp_imp_err = 1 - np.minimum(disp_imp, 1/disp_imp)\n",
    "plot(thresh_arr, 'Classification Thresholds',\n",
    "     val_metrics['bal_acc'], 'Balanced Accuracy',\n",
    "     disp_imp_err, '1 - min(DI, 1/DI)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plot(thresh_arr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification Thresholds\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 2\u001b[0m      \u001b[43mval_metrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbal_acc\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalanced Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m      val_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_odds_diff\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg. odds diff.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "plot(thresh_arr, 'Classification Thresholds',\n",
    "     val_metrics['bal_acc'], 'Balanced Accuracy',\n",
    "     val_metrics['avg_odds_diff'], 'avg. odds diff.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_metrics(metrics, thresh_arr):\n",
    "    best_ind = np.argmax(metrics['bal_acc'])\n",
    "    print(\"Threshold corresponding to Best balanced accuracy: {:6.4f}\".format(thresh_arr[best_ind]))\n",
    "    print(\"Best balanced accuracy: {:6.4f}\".format(metrics['bal_acc'][best_ind]))\n",
    "#     disp_imp_at_best_ind = np.abs(1 - np.array(metrics['disp_imp']))[best_ind]\n",
    "    disp_imp_at_best_ind = 1 - min(metrics['disp_imp'][best_ind], 1/metrics['disp_imp'][best_ind])\n",
    "    print(\"Corresponding 1-min(DI, 1/DI) value: {:6.4f}\".format(disp_imp_at_best_ind))\n",
    "    print(\"Corresponding average odds difference value: {:6.4f}\".format(metrics['avg_odds_diff'][best_ind]))\n",
    "    print(\"Corresponding statistical parity difference value: {:6.4f}\".format(metrics['stat_par_diff'][best_ind]))\n",
    "    print(\"Corresponding equal opportunity difference value: {:6.4f}\".format(metrics['eq_opp_diff'][best_ind]))\n",
    "    print(\"Corresponding Theil index value: {:6.4f}\".format(metrics['theil_ind'][best_ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_metrics(val_metrics, thresh_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_orig_metrics = test(dataset=dataset_orig_panel19_test,\n",
    "                       model=lr_orig_panel19,\n",
    "                       thresh_arr=[thresh_arr[lr_orig_best_ind]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_metrics(lr_orig_metrics, [thresh_arr[lr_orig_best_ind]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
